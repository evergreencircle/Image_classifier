{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'train', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# The code was tested on local machine with Python 3.6.8.  \n",
    "# The model was trained on 1600 samples (800 dogs and 800 cats), verified on 400 samples. \n",
    "# It was tested on manually labelled by me 100 samples and gave accuracy 78%. \n",
    "# The metric has to impove significantly after training on the whole dataset.  \n",
    "\n",
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define constants\n",
    "\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "\n",
    "# Use this code for traning on a part of the samples\n",
    "\n",
    "# prepare traning data with 2000 samples: 50% dogs, 50% cats\n",
    "#TRAIN_DIR = 'input/train/'\n",
    "#TEST_DIR = 'input/test/'\n",
    "\n",
    "#train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "#train_dogs =   [i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "#train_cats =   [i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "#test_images =  [i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "#train_images = train_dogs[:1000] + train_cats[:1000]\n",
    "#random.shuffle(train_images)\n",
    "\n",
    "#categories = []\n",
    "#for filename in train_images:\n",
    "    #category = filename.split('.')[0]\n",
    "    #if 'dog' in category :\n",
    "        #categories.append(1)\n",
    "    #else:\n",
    "        #categories.append(0)\n",
    "\n",
    "#df = pd.DataFrame({\n",
    "    #'filename': train_images,\n",
    "    #'category': categories\n",
    "#})\n",
    "\n",
    "\n",
    "\n",
    "# Prepare traning data\n",
    "\n",
    "filenames = os.listdir(\"input/train\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "# Vizualize training data\n",
    "\n",
    "#df['category'].value_counts().plot.bar()\n",
    "\n",
    "#sample = random.choice(filenames)\n",
    "#image = load_img(\"input/train/\" + sample)\n",
    "#plt.imshow(image)\n",
    "\n",
    "# Build model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Make callbacks\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "\n",
    "# Prepare data\n",
    "\n",
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n",
    "\n",
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=15\n",
    "\n",
    "# Vizualize train and validation samples\n",
    "\n",
    "#train_df['category'].value_counts().plot.bar()\n",
    "#validate_df['category'].value_counts().plot.bar()\n",
    "\n",
    "\n",
    "# Trainig generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"input/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"input/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# See how generator work\n",
    "\n",
    "#example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "#example_generator = train_datagen.flow_from_dataframe(\n",
    "    #example_df, \n",
    "    #\"input/train/\", \n",
    "    #x_col='filename',\n",
    "    #y_col='category',\n",
    "    #target_size=IMAGE_SIZE,\n",
    "    #class_mode='categorical'\n",
    "#)\n",
    "\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#for i in range(0, 15):\n",
    "    #plt.subplot(5, 3, i+1)\n",
    "    #for X_batch, Y_batch in example_generator:\n",
    "        #image = X_batch[0]\n",
    "        #plt.imshow(image)\n",
    "        #break\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# Fit model\n",
    "\n",
    "epochs=3 if FAST_RUN else 50\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save_weights(\"model.h1\")\n",
    "\n",
    "# Vizualize loss and varification of training and verification\n",
    "#fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "#ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "#ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "#ax1.set_xticks(np.arange(1, epochs, 1))\n",
    "#ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "#ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "#ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "#ax2.set_xticks(np.arange(1, epochs, 1))\n",
    "\n",
    "#legend = plt.legend(loc='best', shadow=True)\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Use this code for testing on a part of the samples\n",
    "\n",
    "#prepare testing data with 100 samples\n",
    "#test_images =  test_images[:100]\n",
    "#test_df = pd.DataFrame({\n",
    "    #'filename': test_images\n",
    "#})\n",
    "#nb_samples = test_df.shape[0]\n",
    "\n",
    "# Prepare testing data\n",
    "\n",
    "test_filenames = os.listdir(\"input/test\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "\n",
    "# Create testing generator\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"input/test\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Predict\n",
    "\n",
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "\n",
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "# Vizualize results \n",
    "\n",
    "#test_df['category'].value_counts().plot.bar()\n",
    "\n",
    "# Results \n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })\n",
    "\n",
    "submission_df = test_df.copy()\n",
    "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Code for visualizing results of testing for 100 images\n",
    "\n",
    "#sample_test = test_df\n",
    "#sample_test.head()\n",
    "#plt.figure(figsize=(12, 100))\n",
    "#for index, row in sample_test.iterrows():\n",
    "    #filename = row['filename']\n",
    "    #category = row['category']\n",
    "    #img = load_img(\"input/test/\"+filename, target_size=IMAGE_SIZE)\n",
    "    #plt.subplot(34, 3, index+1)\n",
    "    #plt.imshow(img)\n",
    "    #plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
